{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrThyC/RfliHvaoASKf2wo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fAy8o2YWWfZ",
        "outputId": "4b05ec9c-5018-448d-cbc9-14f9d670d9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to tokenize the text\n",
        "def tokenize(text):\n",
        "  return text.lower().split()"
      ],
      "metadata": {
        "id": "e7YYFEsVWZCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to calculate term frequency (TF)\n",
        "def tf(term, tokenized_document):\n",
        "  return tokenized_document.count(term) / len(document)\n"
      ],
      "metadata": {
        "id": "ncFS-jizWb42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to calculate inverse document frequency(IDF)\n",
        "def inverse_document_frequency(term, all_documents):\n",
        "  num_docs_containing_term = sum(1 for doc in all_documents if term in doc)\n",
        "  return math.log(len(all_documents) / (1 + num_documents_term))"
      ],
      "metadata": {
        "id": "xulpy-VKXHtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to compute cosine similarity between two vector\n",
        "def cosine_similarity(vector1, vector2):\n",
        "  dot_product = np.dot(vector1, vector2)\n",
        "  magnitude1 = np.linalg.norm(vector1)\n",
        "  magnitude2 = np.linalg.norm(vector2)\n",
        "  return dot_product / (norm_vec1 * norm_vec2)"
      ],
      "metadata": {
        "id": "4-hdnYh8XLYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to compute TF-IDF For a document\n",
        "def compute_tfidf(document, all_documents, vocab):\n",
        "  tfidf_vector = []\n",
        "  for term in vocab:\n",
        "    tf = term_frequencu(term, document)\n",
        "    idf = inverse_document_frequency(term, all_documents)\n",
        "    tfidf_vector.append(tf * idf)\n",
        "  return np.array(tfidf_vector)"
      ],
      "metadata": {
        "id": "HSUr-z_wXOhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Define a simple tokenizer function (replace this with your actual tokenizer)\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# Function to compute TF-IDF vectors\n",
        "def compute_tfidf(corpus, queries):\n",
        "    vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
        "    doc_tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "    query_tfidf_matrix = vectorizer.transform(queries)\n",
        "    return doc_tfidf_matrix, query_tfidf_matrix\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Directory containing the text documents\n",
        "    directory = '/content/drive/MyDrive/Vector Retrieval System Document'\n",
        "\n",
        "    # Reading all files from the directory\n",
        "    docs = []\n",
        "    filenames = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(os.path.join(directory, filename), \"r\", encoding='latin-1') as file: # Changed encoding to latin-1, you may need to try others like 'cp1252'\n",
        "                content = file.read()\n",
        "                docs.append(content)\n",
        "                filenames.append(filename)\n",
        "\n",
        "    # Hardcoded queries\n",
        "    queries = ['time', 'time universe', 'complex time universe']\n",
        "\n",
        "    # Compute TF-IDF vectors for documents and queries\n",
        "    doc_tfidf_matrix, query_tfidf_matrix = compute_tfidf(docs, queries)\n",
        "\n",
        "    # Calculate cosine similarities\n",
        "    cosine_similarities = cosine_similarity(query_tfidf_matrix, doc_tfidf_matrix)\n",
        "\n",
        "    # Write the ranked results to a text file\n",
        "    with open(\"cosine_similarities_ranked_results.txt\", \"w\") as output_file:\n",
        "        for i, query in enumerate(queries):\n",
        "            output_file.write(f\"\\nRanked cosine similarities for query '{query}':\\n\")\n",
        "\n",
        "            # Pair document filenames with their similarity scores\n",
        "            doc_similarity_pairs = list(zip(filenames, cosine_similarities[i]))\n",
        "            # Sort by similarity in descending order\n",
        "            ranked_docs = sorted(doc_similarity_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Write ranked results\n",
        "            for rank, (filename, score) in enumerate(ranked_docs, 1):\n",
        "                output_file.write(f\"Rank {rank}: Document {filename} - Score: {score:.4f}\\n\")\n",
        "\n",
        "    # Optional: print ranked results for checking\n",
        "    for i, query in enumerate(queries):\n",
        "        print(f\"\\nRanked cosine similarities for query '{query}':\")\n",
        "\n",
        "        # Pair document filenames with their similarity scores\n",
        "        doc_similarity_pairs = list(zip(filenames, cosine_similarities[i]))\n",
        "        # Sort by similarity in descending order\n",
        "        ranked_docs = sorted(doc_similarity_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Print ranked results\n",
        "        for rank, (filename, score) in enumerate(ranked_docs, 1):\n",
        "            print(f\"Rank {rank}: Document {filename} - Score: {score:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfRslQRLXcF3",
        "outputId": "862d20f6-b2fd-4843-cae5-b36d32b9c259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ranked cosine similarities for query 'time':\n",
            "Rank 1: Document doc 2.txt - Score: 0.0000\n",
            "Rank 2: Document doc8.txt - Score: 0.0000\n",
            "Rank 3: Document doc6.txt - Score: 0.0000\n",
            "Rank 4: Document doc3.txt - Score: 0.0000\n",
            "Rank 5: Document doc7.txt - Score: 0.0000\n",
            "Rank 6: Document doc10.txt - Score: 0.0000\n",
            "Rank 7: Document doc4.txt - Score: 0.0000\n",
            "Rank 8: Document doc 1.txt - Score: 0.0000\n",
            "Rank 9: Document doc5.txt - Score: 0.0000\n",
            "Rank 10: Document doc9.txt - Score: 0.0000\n",
            "\n",
            "Ranked cosine similarities for query 'time universe':\n",
            "Rank 1: Document doc 2.txt - Score: 0.0000\n",
            "Rank 2: Document doc8.txt - Score: 0.0000\n",
            "Rank 3: Document doc6.txt - Score: 0.0000\n",
            "Rank 4: Document doc3.txt - Score: 0.0000\n",
            "Rank 5: Document doc7.txt - Score: 0.0000\n",
            "Rank 6: Document doc10.txt - Score: 0.0000\n",
            "Rank 7: Document doc4.txt - Score: 0.0000\n",
            "Rank 8: Document doc 1.txt - Score: 0.0000\n",
            "Rank 9: Document doc5.txt - Score: 0.0000\n",
            "Rank 10: Document doc9.txt - Score: 0.0000\n",
            "\n",
            "Ranked cosine similarities for query 'complex time universe':\n",
            "Rank 1: Document doc4.txt - Score: 0.0976\n",
            "Rank 2: Document doc9.txt - Score: 0.0627\n",
            "Rank 3: Document doc3.txt - Score: 0.0546\n",
            "Rank 4: Document doc6.txt - Score: 0.0515\n",
            "Rank 5: Document doc 2.txt - Score: 0.0000\n",
            "Rank 6: Document doc8.txt - Score: 0.0000\n",
            "Rank 7: Document doc7.txt - Score: 0.0000\n",
            "Rank 8: Document doc10.txt - Score: 0.0000\n",
            "Rank 9: Document doc 1.txt - Score: 0.0000\n",
            "Rank 10: Document doc5.txt - Score: 0.0000\n"
          ]
        }
      ]
    }
  ]
}